# Projects
  
- name: testProjectName
  authors: a, b, c, d
  img: https://raw.githubusercontent.com/NLPLearn/QANet/master/screenshots/figure.png
  intro: A Tensorflow implementation of Google's QANet (previously Fast Reading Comprehension (FRC)) from ICLR2018.
  code: https://github.com/NLPLearn/QANet
  pdf: https://arxiv.org/pdf/1804.09541.pdf
  data: https://nlp.stanford.edu/software/GloVe-1.2.zip
  training: https://github.com/i-lovelife/test-private-repo
  visible: false

- name: Gated-GAN&#58; Adversarial Gated Networks for Multi-Collection Style Transfer
  authors: Xinyuan Chen, Chang Xu, Xiaokang Yang, Li Song, Dacheng Tao
  img: https://github.com/xinyuanc91/Gated-GAN/raw/master/imgs/architecture.jpg
  intro: We propose adversarial gated networks (Gated-GAN) to transfer multiple styles in a single model. The generative networks have three modules&#58; an encoder, a gated transformer, and a decoder. Different styles can be achieved by passing input images through different branches of the gated transformer.
  code: https://github.com/xinyuanc91/Gated-GAN
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8463508

- name: Continuous Dropout
  authors: Xu Shen, Xinmei Tian, Tongliang Liu, Fang Xu, Dacheng Tao
  intro: According to the activation patterns of neurons in the human brain, when faced with different situations, the firing rates of neurons are random and continuous, not binary as current dropout does. Inspired by this phenomenon, we extend the traditional binary dropout to continuous dropout. On the one hand, continuous dropout is considerably closer to the activation characteristics of neurons in the human brain than traditional binary dropout. On the other hand, we demonstrate that continuous dropout has the property of avoiding the co-adaptation of feature detectors, which suggests that we can extract more independent feature detectors for model averaging in the test stage.
  code: https://github.com/jasonustc/caffe-multigpu/tree/dropout
  pdf: https://ieeexplore.ieee.org/document/8057594
  data: MNIST, CIFAR10, IMAGENET

- name: Multi-Task Learning for Blind Source Separation
  authors: Bo Du, Shaodong Wang, Chang Xu, Nan Wang, Liangpei Zhang, Dacheng Tao
  intro: In this paper, we propose a new algorithm named multi-task sparse model to solve the BSS problem. Source signals are characterized via sparse techniques. Meanwhile, we regard the decomposition of each mixture signal as a task and employ the idea of multi-task learning to discover connections between tasks for the accuracy improvement of the source signal separation. Theoretical analyses on the optimization convergence and sample complexity of the proposed algorithm are provided. Experimental results based on extensive synthetic and real-world data demonstrate the necessity of exploiting connections between mixture signals and the effectiveness of the proposed algorithm
  code: https://github.com/532806389/Multi-Task-Learning-for-Blind-Source-Separation
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8359085

- name: Multi-task model and feature joint learning
  authors: Ya Li, Xinmei Tian, Tongliang Liu, Dacheng Tao
  intro: A matlab implementation for work “On Better Exploring and Exploiting Task Relationships in Multi-Task Learning&#58; Joint Model and Feature Learning” from TNNLS.
  code: https://github.com/YaLeeUSTC/MTMF
  pdf: https://ieeexplore.ieee.org/document/7902220

- name: Heterogeneous Multitask Metric Learning Across Multiple Domains
  authors: Yong Luo, Yonggang Wen, Dacheng Tao
  img: https://raw.githubusercontent.com/yluopku/HMTML/master/System_Diagram.png
  intro: A Matlab implementation of the heterogeneous multi-task metric learning method from IEEE TNNLS 2018 (Heterogeneous Multitask Metric Learning Across Multiple Domains) and IJCAI 2016 (On Combining Side Information and Unlabeled Data for Heterogeneous Multi-Task Metric Learning).
  code: https://github.com/yluopku/HMTML
  pdf: https://www.ijcai.org/Proceedings/16/Papers/259.pdf

- name: CostSentitiveFeatureSelection
  authors: Meng Liu, Chang Xu, Yong Luo, Chao Xu, Yonggang Wen, Dacheng Tao
  intro: A Matlab Implementation for paper Cost-Sensitive Feature Selection by Optimizing F-Measures from TIP2017.
  code: https://github.com/lemolemac/CostSentitiveFeatureSelection
  pdf: accepted version has been wechated to XiaoFei

- name: Shakeout&#58; A New Approach to Regularized Deep Neural Network Training
  authors: Guoliang Kang, Jun Li, Dacheng Tao
  intro: A Caffe implementation of Shakeout from AAAI 2016 and T-PAMI 2018.
  code: https://github.com/kgl-prml/shakeout-for-caffe
  pdf: https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/viewPaper/11840

- name: MahNMF&#58; Manhattan Non-negative Matrix Factorization
  authors: Naiyang Guan, Dacheng Tao, Zhigang Luo, John Shawe-Taylor
  intro: This paper presents Manhattan NMF (MahNMF) which minimizes the Manhattan distance between X and WTH for modeling the heavy tailed Laplacian noise. Similar to sparse and low-rank matrix decompositions, e.g. robust principal component analysis (RPCA) and GoDec, MahNMF robustly estimates the low-rank part and the sparse part of a non-negative matrix and thus performs effectively when data are contaminated by outliers. We extend MahNMF for various practical applications by developing box-constrained MahNMF, manifold regularized MahNMF, group sparse MahNMF, elastic net inducing MahNMF, and symmetric MahNMF.
  code: https://sites.google.com/site/nmfsolvers/documents/ManhNMF.rar?attredirects=0
  pdf: https://sites.google.com/site/nmfsolvers/documents/MahNMF%20Manhattan%20Non-negative%20Matrix%20Factorization.pdf?attredirects=0

- name: Online Nonnegative Matrix Factorization With Robust Stochastic Approximation
  authors: Naiyang Guan, Dacheng Tao, Zhigang Luo, Bo Yuan
  intro: In this paper, we propose an efficient online RSA-NMF algorithm (OR-NMF) that learns NMF in an incremental fashion and thus solves this problem.
  pdf: https://sites.google.com/site/nmfsolvers/documents/Online%20Nonnegative%20Matrix%20Factorization%20With%20Robust%20Stochastic%20Approximation.pdf?attredirects=0

- name: NeNMF&#58; An Optimal Gradient Method for Nonnegative Matrix Factorization
  authors: Naiyang Guan, Dacheng Tao, Zhigang Luo, Bo Yuan
  intro: In this paper, we present a new efficient NeNMF solver to simultaneously overcome the aforementioned problems. It applies Nesterov's optimal gradient method to alternatively optimize one factor with another fixed. In particular, at each iteration round, the matrix factor is updated by using the PG method performed on a smartly chosen search point, where the step size is determined by the Lipschitz constant.
  pdf: https://sites.google.com/site/nmfsolvers/documents/NeNMF%20An%20Optimal%20Gradient%20Method%20for%20Nonnegative%20Matrix%20Factorization.pdf?attredirects=0
  code: https://sites.google.com/site/nmfsolvers/documents/NeNMF.rar?attredirects=0

- name: Manifold Regularized Discriminative Nonnegative Matrix Factorization With Fast Gradient Descent
  authors: Naiyang Guan, Dacheng Tao, Zhigang Luo, Bo Yuan
  intro: In this paper, we introduce the manifold regularization and the margin maximization to NMF and obtain the manifold regularized discriminative NMF (MD-NMF) to overcome the aforementioned problems.
  pdf: https://sites.google.com/site/nmfsolvers/documents/Manifold%20Regularized%20Discriminative%20Nonnegative%20Matrix%20Factorization%20With%20Fast%20Gradient%20Descent.pdf?attredirects=0

- name: Non-Negative Patch Alignment Framework
  authors: Naiyang Guan, Dacheng Tao, Zhigang Luo, Bo Yuan
  intro: In this paper, we present a non-negative patch alignment framework (NPAF) to unify popular non-negative matrix factorization (NMF) related dimension reduction algorithms. It offers a new viewpoint to better understand the common property of different NMF algorithms.
  pdf: https://sites.google.com/site/nmfsolvers/documents/Non-Negative%20Patch%20Alignment%20Framework.pdf?attredirects=0
  code: https://sites.google.com/site/nmfsolvers/documents/NPAF%20%28M-code%29.rar?attredirects=0

- name: Real-time Video Dehazing based on Spatio-temporal MRF
  authors: Bolun Cai, Xiangmin Xu, Dacheng Tao
  intro: We build a Markov Random Field (MRF) with an Intensity Value Prior (IVP) to handle spatial consistency and temporal coherence.
  pdf: https://link.springer.com/content/pdf/10.1007%2F978-3-319-48896-7.pdf
  code: https://github.com/caibolun/ST-MRF

- name: A Joint Intrinsic-Extrinsic Prior Model for Retinex
  authors: Bolun Cai, Xianming Xu, Kailing Guo, Kui Jia, Bin Hu, Dacheng Tao
  intro: We propose a joint intrinsic-extrinsic prior model to estimate both illumination and reflectance from an observed image.
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8237693
  code: https://github.com/caibolun/JieP#a-joint-intrinsic-extrinsic-prior-model-for-retinex

- name: BIT&#58; Biologically Inspired Tracker
  authors: Bolun Cai, Xiangmin Xu, Xiaofen Xing, Kui Jia, Jie Miao and Dacheng Tao
  intro: This paper aims to address this challenge based on the analysis of visual cognitive mechanism of the ventral stream in the visual cortex, which simulates shallow neurons (S1 units and C1 units) to extract low-level biologically inspired features for the target appearance and imitates an advanced learning mechanism (S2 units and C2 units) to combine generative and discriminative models for target location.
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7387745
  code: https://github.com/caibolun/BIT

- name: DehazeNet&#58; An End-to-End System for Single Image Haze Removal
  authors: Bolun Cai, Xiangmin Xu, Kui Jia, Chunmei Qing, Dacheng Tao, [Lingke Zeng]
  intro: Single image haze removal is a challenging ill-posed problem. Existing methods use various constraints/priors to get plausible dehazing solutions. The key to achieve haze removal is to estimate a medium transmission map for an input hazy image. In this paper, we propose a trainable end-to-end system called DehazeNet, for medium transmission estimation. DehazeNet takes a hazy image as input, and outputs its medium transmission map that is subsequently used to recover a haze-free image via atmospheric scattering model. DehazeNet adopts Convolutional Neural Networks (CNN) based deep architecture, whose layers are specially designed to embody the established assumptions/priors in image dehazing. Specifically, layers of Maxout units are used for feature extraction, which can generate almost all haze-relevant features. We also propose a novel nonlinear activation function in DehazeNet, called Bilateral Rectified Linear Unit (BReLU), which is able to improve the quality of recovered haze-free image. We establish connections between components of the proposed DehazeNet and those used in existing methods. Experiments on benchmark images show that DehazeNet achieves superior performance over existing methods, yet keeps efficient and easy to use.
  pdf: https://arxiv.org/pdf/1601.07661.pdf
  code: https://github.com/caibolun/DehazeNet

- name: Go Decomposition (GoDec)&#58; Randomized Low-rank and Sparse Matrix Decomposition in Noisy Case; 
  authors: Tianyi Zhou, Dacheng Tao
  intro: Low-rank and sparse structures have been profoundly studied in matrix completion and compressed sensing. In this paper, we develop ``Go Decomposition'' (GoDec) to efficiently and robustly estimate the low-rank part $L$ and the sparse part $S$ of a matrix $X=L+S+G$ with noise $G$. GoDec alternatively assigns the low-rank approximation of $X-S$ to $L$ and the sparse approximation of $X-L$ to $S$. The algorithm can be significantly accelerated by bilateral random projections (BRP). We also propose GoDec for matrix completion as an important variant. We prove that the objective value $\|X-L-S\|_F^2$ converges to a local minimum, while $L$ and $S$ linearly converge to local optimums. Theoretically, we analyze the influence of $L$, $S$ and $G$ to the asymptotic/convergence speeds in order to discover the robustness of GoDec. Empirical studies suggest the efficiency, robustness and effectiveness of GoDec comparing with representative matrix decomposition and completion tools, e.g., Robust PCA and OptSpace.
  pdf: http://www.icml-2011.org/papers/41_icmlpaper.pdf
  code: https://sites.google.com/site/godecomposition/code

- name: Multi-modal Factorized Bilinear Pooling with Co-Attention Learning for Visual Question Answering 
  authors: Zhou Yu, Jun Yu, Jianping Fan, Dacheng Tao
  intro: This project is the implementation of the papers Multi-modal Factorized Bilinear Pooling with Co-Attention Learning for Visual Question Answering (MFB) and Beyond Bilinear&#58; Generalized Multi-modal Factorized High-order Pooling for Visual Question Answering (MFH). Compared with existing state-of-the-art approaches such as MCB and MLB, our MFB models achieved superior performance on the large-scale VQA-1.0 and VQA-2.0 datasets. Moreover, MFH, the high-order extention of MFB, is also proveided to report better VQA performance. The MFB(MFH)+CoAtt network architecture for VQA is illustrated in Figure 1.
  pdf: https://arxiv.org/pdf/1708.01471.pdf
  code: https://github.com/yuzcccc/vqa-mfb

- name: Multi-View Intact Space Learning
  authors: Chang Xu, Dacheng Tao, Chao Xu
  intro: A multi-view learning algorithm which integrates the encoded complementary information in multiple views to discover a latent intact representation of the data.
  code: https://1drv.ms/f/s!AiyWUTcV8QW4fnwBgRsB6DtUkys
  pdf: https://ieeexplore.ieee.org/document/7297854

- name: Large-Margin Multi-View Information Bottleneck
  authors: Chang Xu, Dacheng Tao, Chao Xu
  intro: An extension of the theory of the information bottleneck (IB) to learning from examples represented by multi-view features.
  code: https://1drv.ms/f/s!AiyWUTcV8QW4gQIOImu4LU6jKPh4
  pdf: https://ieeexplore.ieee.org/document/6697863

- name: One-Pass Multi-task Convolutional Neural Networks for Efficient Brain Tumor Segmentation 
  authors: Chenhong Zhou, Changxing Ding, Zhentai Lu, Xinchao Wang and Dacheng Tao
  intro: This work overcomes the shortcomings of popular model cascade strategy that can lead to undesired system complexity and ignore the relevance among the models due to its multiple separate cascaded models. We propose to adopt multi-task learning to integrate multiple segmentation tasks into a deep model which is called One-pass Multi-task Network (OM-Net).
  pdf: https://link.springer.com/content/pdf/10.1007%2F978-3-030-00931-1_73.pdf
  code: https://github.com/chenhong-zhou/OM-Net

- name: BAG
  authors: Yu Cao, Meng Fang, Dacheng Tao
  img: https://github.com/caoyu1991/BAG/blob/master/BAG.png
  intro: Pytorch implementation for NAACL-2019 paper BAG&#58; Bi-directional Attention Entity Graph Convolutional Network forMulti-hop Reasoning Question Answering
  code: https://github.com/caoyu1991/BAG
  pdf: https://arxiv.org/abs/1904.04969
  data: https://drive.google.com/file/d/1ytVZ4AhubFDOEL7o7XrIRIyhU8g9wvKA/view

- name: Geometry-Aware Symmetric Domain Adaptation for Monocular Depth Estimation
  authors: Shanshan Zhao, Huan Fu, Mingming Gong, and Dacheng Tao
  intro: In this paper, we propose a geometry-aware symmetric domain adaptation framework (GASDA) to explore the labels in the synthetic data and epipolar geometry in the real data jointly. Moreover, by training two image style translators and depth estimators symmetrically in an end-to-end network, our model achieves better image style transfer and generates high-quality depth maps. The experimental results demonstrate the effectiveness of our proposed method and comparable performance against the state-of-the-art. 
  code: https://github.com/sshan-zhao/GASDA
  pdf: https://arxiv.org/abs/1904.01870

- name: MUlti-Store Tracker (MUSTer)&#58; a Cognitive Psychology Inspired Approach to Object Trackingauthors 
  authors: Zhibin Hong, Zhe Chen, Chaohui Wang, Xue Mei, Danil Prokhorov, and Dacheng Tao
  img: https://sites.google.com/site/zhibinhong4131/Projects/muster/FinalFlow_01~1.png?attredirects=0
  intro: Variations in the appearance of a tracked object, such as changes in geometry/photometry, camera viewpoint, illumination, or partial occlusion, pose a major challenge to object tracking. Here, we adopt cognitive psychology principles to design a flexible representation that can adapt to changes in object appearance during tracking. Inspired by the well-known Atkinson-Shiffrin Memory Model, we propose MUlti-Store Tracker (MUSTer), a dual-component approach consisting of short- and long-term memory stores to process target appearance memories. A powerful and efficient Integrated Correlation Filter (ICF) is employed in the short-term store for short-term tracking. The integrated long-term component, which is based on keypoint matching-tracking and RANSAC estimation, can interact with the long-term memory and provide additional information for output control. MUSTer was extensively evaluated on the CVPR2013 Online Object Tracking Benchmark (OOTB) and ALOV++ datasets. The experimental results demonstrated the superior performance of MUSTer in comparison with other state-of-art trackers.  
  code: https://sites.google.com/site/zhibinhong4131/MUSTer_code_v1.1.zip?attredirects=0&d=1
  pdf: https://sites.google.com/site/multistoretrackermuster/MUlti-Store%20Tracker%20%28MUSTer%29%20a%20Cognitive%20Psychology%20Inspired%20Approach%20to%20Object%20Tracking.pdf?attredirects=0&d=1
  datasets: 
    - url: https://sites.google.com/site/trackerbenchmark/benchmarks/v10
      name: OTB-50
    - url: http://www.google.com/url?q=http%3A%2F%2Fimagelab.ing.unimore.it%2Fdsm%2Findex.php%3FItemid%3D105&sa=D&sntz=1&usg=AFrqEzfxJTaBFIaAk-GF5rgg8JVmvwuFEA
      name: ALOV300++

- name: Perceptual Adversarial Networks for Image-to-Image Transformation
  authors: Chaoyue Wang, Chang Xu, Chaohui Wang, Dacheng Tao
  intro: A Theano implementation of Perceptual Adversarial Networks(PAN).
  code: https://github.com/WANG-Chaoyue/PAN
  pdf: https://arxiv.org/pdf/1706.09138.pdf

- name: Evolutionary Generative Adversarial Networks
  authors: Chaoyue Wang, Chang Xu, Xin Yao, Dacheng Tao
  intro: A Theano implementations for Evolutionary Generative Adversarial Networks (E-GAN).
  code: https://github.com/WANG-Chaoyue/EvolutionaryGAN
  pdf: https://arxiv.org/pdf/1803.00657.pdf

- name: World from Blur
  authors: Jiayan Qiu, Xinchao Wang, Stephen J. Maybank, Dacheng Tao
  intro: What can we tell from a single motion-blurred image? We show in this paper that a 3D scene can berevealed. Unlike prior methods that focus on producing a deblurred image, we propose to estimate and take advantage of the hidden spatial information of a blurred image to restore the 3D scene collapsed during the exposure process. We accomplish this via training a deep network of three modules—one deblurring module to obtain deblurred image, one motion estimation module to extract the relative camera trajectory embedded in blurred image, and one depth estimation module to estimate the absolutely scale depth map of the deblurred image. Then, these three modules form a cycle to in turn reproduce the input blurred image and supervise one another. To this end, the proposed method enabling plausible 3D scene reconstruction from a single blurred image. Moreover, the performance of the three modules are enhanced by each other. We test the proposed model on several large-scale datasets we constructed based on benchmarks, as well as real-world blurred images, and show that it yields very encouraging quantitative and qualitative results. In the future work, we will endeavor to estimate dynamic scenes from single blurred images, and incorporate more tasks like scene parsing into the framework.
  code: https://github.com/JiayanQ/WfB 
  data: https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html
